// scripts/run-scan.js
require('dotenv').config({ path: '.env.local' });
const { ApifyClient } = require('apify-client');
const { createClient } = require('@supabase/supabase-js');

// 1. Káº¿t ná»‘i Supabase & Apify
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;
const apifyToken = process.env.APIFY_API_TOKEN;

if (!supabaseUrl || !supabaseKey || !apifyToken) {
    console.error("âŒ Thiáº¿u biáº¿n mÃ´i trÆ°á»ng! Kiá»ƒm tra file .env.local");
    process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);
const apify = new ApifyClient({ token: apifyToken });

// HÃ m tÃ­nh Ä‘iá»ƒm PageSpeed giáº£ Ä‘á»‹nh (VÃ¬ check tháº­t tá»‘n thÃªm API khÃ¡c, ta táº¡m random logic dá»±a trÃªn website)
function estimatePageSpeed(url) {
    if (!url) return 0;
    // Web khÃ´ng cÃ³ https thÆ°á»ng cÅ© vÃ  cháº­m
    if (!url.startsWith('https')) return Math.floor(Math.random() * 30); 
    return Math.floor(Math.random() * 60) + 40; // Random 40-100
}

async function runScraper(keyword) {
    console.log(`ðŸš€ Báº¯t Ä‘áº§u quÃ©t Google Maps vá»›i tá»« khÃ³a: "${keyword}"...`);

    // 2. Cáº¥u hÃ¬nh Input cho Apify (Google Maps Scraper)
    const runInput = {
        "searchStrings": [keyword],
        "locationQuery": "", 
        "maxCrawledPlacesPerSearch": 5, // Test trÆ°á»›c 5 cÃ¡i cho nhanh
        "language": "en",
    };

    try {
        // 3. Call Apify Actor (google-maps-scraper)
        // Actor ID of Google Maps Scraper is 'compass/crawler-google-places' 
        // Use the most common one: 'nwua9Gu5YrADL7ZUj' (Google Maps Scraper)
        console.log("â³ Calling Apify Actor (may take 30-60 seconds)...");
        
        const run = await apify.actor("nwua9Gu5YrADL7ZUj").call(runInput);
        
        console.log(`âœ… Scratching complete! Loading data from Dataset: ${run.defaultDatasetId}`);
        const { items } = await apify.dataset(run.defaultDatasetId).listItems();

        if (items.length === 0) {
            console.log("âš ï¸ No results found.");
            return;
        }

        // 4. Process and save to Supabase
        console.log(`ðŸ’¾ Saving company ${items.length} to the database...`);
        
        const companies = items.map(item => {
            const hasSSL = item.website ? item.website.startsWith('https') : false;
            const score = estimatePageSpeed(item.website);
            // Scan logic: if PageSpeed < 50 or no SSL then qualified
            const isQualified = score < 50 || !hasSSL; 

            return {
                name: item.title,
                website_url: item.website || null,
                google_maps_url: item.url,
                industry: item.categoryName || keyword,
                address: item.address,
                phone_number: item.phone,
                has_ssl: hasSSL,
                pagespeed_score: score,
                status: isQualified ? 'QUALIFIED' : 'DISQUALIFIED',
                disqualify_reason: isQualified ? null : 'Website looks good',
            };
        });

        // Insert each item individually to avoid duplicate errors (or use upsert if necessary).
        const { error } = await supabase.from('companies').insert(companies);

        if (error) {
            console.error("âŒ Supabase save error:", error);
        } else {
            console.log("ðŸŽ‰ Success! Data has been uploaded to the Dashboard.");
        }

    } catch (error) {
        console.error("âŒ Scraper Error:", error);
    }
}

// Get keywords from the command line.
const keywordArg = process.argv[2];
if (!keywordArg) {
    console.log("âš ï¸ Enter the keyword. E.g: node scripts/run-scan.js \"Coffee shop in Hanoi\"");
} else {
    runScraper(keywordArg);
}